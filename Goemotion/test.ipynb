{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "with open('./data/ekman/labels.txt', 'r', encoding='utf-8') as file:\n",
    "    labels = [line.strip() for line in file]\n",
    "print(labels)\n",
    "\n",
    "def convert_class_label(label):\n",
    "    try:\n",
    "        return labels[int(label)]\n",
    "    except (ValueError, IndexError):\n",
    "        return label  # If label is not valid, keep it unchanged\n",
    "    \n",
    "# 生成標籤的 .pkl 檔案\n",
    "def generate_label_vocab(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        labels = [line.strip() for line in f.readlines()]\n",
    "    label_vocab = {label: idx for idx, label in enumerate(labels)}\n",
    "    torch.save(label_vocab, './label_vocab.pkl')\n",
    "    print(f\"Label vocabulary saved to './label_vocab.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label vocabulary saved to './label_vocab.pkl'\n"
     ]
    }
   ],
   "source": [
    "generate_label_vocab('./data/ekman/labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/ekman/train.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])\n",
    "test_data = pd.read_csv(\"./data/ekman/train.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])\n",
    "dev_data = pd.read_csv(\"./data/ekman/train.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Class List'] = train_data['Class'].apply(lambda x: x.split(','))\n",
    "# train_data['Class Length'] = train_data['Class List'].apply(lambda x: len(x))\n",
    "train_data = train_data.drop(columns=['ID'])\n",
    "\n",
    "dev_data['Class List'] = dev_data['Class'].apply(lambda x: x.split(','))\n",
    "# dev_data['Class Length'] = dev_data['Class List'].apply(lambda x: len(x))\n",
    "dev_data = dev_data.drop(columns=['ID'])\n",
    "\n",
    "test_data['Class List'] = test_data['Class'].apply(lambda x: x.split(','))\n",
    "# test_data['Class Length'] = test_data['Class List'].apply(lambda x: len(x))\n",
    "test_data = test_data.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預處理\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # 轉換為小寫\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # 使用正則表達式匹配並移除所有網址\n",
    "    text = re.sub(r'\\@w+|\\#', '', text)  # 移除 @ 和 #\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # 移除所有非字母\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # 移除多餘的空格\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Text'] = train_data['Text'].apply(preprocess_text)\n",
    "dev_data['Text'] = dev_data['Text'].apply(preprocess_text)\n",
    "test_data['Text'] = test_data['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label conversion to each dataset\n",
    "train_data.iloc[:, 1] = train_data.iloc[:, 1].apply(convert_class_label)\n",
    "dev_data.iloc[:, 1] = dev_data.iloc[:, 1].apply(convert_class_label)\n",
    "test_data.iloc[:, 1] = test_data.iloc[:, 1].apply(convert_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>Class List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my favourite food is anything i didnt have to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now if he does off himself everyone will think...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the fuck is bayless isoing</td>\n",
       "      <td>anger</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to make her feel threatened</td>\n",
       "      <td>fear</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dirty southern wankers</td>\n",
       "      <td>anger</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43405</th>\n",
       "      <td>added you mate well ive just got the bow and i...</td>\n",
       "      <td>joy</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43406</th>\n",
       "      <td>always thought that was funny but is it a refe...</td>\n",
       "      <td>surprise</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43407</th>\n",
       "      <td>what are you talking about anything bad that h...</td>\n",
       "      <td>anger</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43408</th>\n",
       "      <td>more like a baptism with sexy results</td>\n",
       "      <td>joy</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43409</th>\n",
       "      <td>enjoy the ride</td>\n",
       "      <td>joy</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text     Class Class List\n",
       "0      my favourite food is anything i didnt have to ...   neutral        [4]\n",
       "1      now if he does off himself everyone will think...   neutral        [4]\n",
       "2                         why the fuck is bayless isoing     anger        [0]\n",
       "3                            to make her feel threatened      fear        [2]\n",
       "4                                 dirty southern wankers     anger        [0]\n",
       "...                                                  ...       ...        ...\n",
       "43405  added you mate well ive just got the bow and i...       joy        [3]\n",
       "43406  always thought that was funny but is it a refe...  surprise        [6]\n",
       "43407  what are you talking about anything bad that h...     anger        [0]\n",
       "43408              more like a baptism with sexy results       joy        [3]\n",
       "43409                                     enjoy the ride       joy        [3]\n",
       "\n",
       "[43410 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "save_path = 'data/ekman/processed'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "train_data.to_csv('./data/ekman/processed/train.tsv', sep='\\t', index=False)\n",
    "dev_data.to_csv('./data/ekman/processed/dev.tsv', sep='\\t', index=False)\n",
    "test_data.to_csv('./data/ekman/processed/test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = train_test_split(train_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義MLP模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc5 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, 28*28)\n",
    "        out = torch.relu(self.bn1(self.fc1(out)))\n",
    "        out = self.dropout1(out)\n",
    "        out = torch.relu(self.bn2(self.fc2(out)))\n",
    "        out = self.dropout2(out)\n",
    "        out = torch.relu(self.bn3(self.fc3(out)))\n",
    "        out = self.dropout3(out)\n",
    "        out = torch.relu(self.bn4(self.fc4(out)))\n",
    "        out = self.dropout4(out)\n",
    "        out = self.fc5(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型的 function\n",
    "def train_model(train_data, train_labels, input_size, hidden_size, output_size, epochs=20, batch_size=32, learning_rate=0.001):\n",
    "    # 將訓練數據包裝為 TensorDataset\n",
    "    dataset = TensorDataset(train_data, train_labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 初始化模型、損失函數和優化器\n",
    "    model = MLP(input_size, hidden_size, output_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 訓練循環\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch_data, batch_labels in dataloader:\n",
    "            # 前向傳播\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "\n",
    "            # 反向傳播和優化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # 每個 epoch 結束後打印損失\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "    print(\"訓練完成!\")\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EACL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
